#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\begin_modules
knitr
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Report on auto-mpg Data Set
\end_layout

\begin_layout Author
Saikat Bera, Presidency University, KOLKATA
\end_layout

\begin_layout Abstract
set auto-mpg.csv, comes from the 1983 American Statistical Association Exposition.
 The response variable of interest is fuel consumption, measured in miles
 per gallon.
 Other attributes of cars like the weight, horsepower, number cylinders,
 and acceleration time were also recorded for each car.
 We will study the relationship between mpg and weight (in lbs).
 
\end_layout

\begin_layout Standard
We first load the dataset and view the first few entries as well as run
 a summary:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=F>>=
\end_layout

\begin_layout Plain Layout

df<-read.csv("E:
\backslash

\backslash
B.Sc.
 Statistics Hons
\backslash

\backslash
College
\backslash

\backslash
6th Sem
\backslash

\backslash
Exploratory Data Analysis
\backslash

\backslash
Data
\backslash

\backslash
auto-mpg.csv") 
\end_layout

\begin_layout Plain Layout

head(df) 
\end_layout

\begin_layout Plain Layout

summary(df) 
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can plot a mpg vs.
 weight scatterplot and find out the relationship between the two variables.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=F>>=
\end_layout

\begin_layout Plain Layout

plot(df$weight,df$mpg, 
\end_layout

\begin_layout Plain Layout

     xlab='Weight', ylab='mpg', 
\end_layout

\begin_layout Plain Layout

     main='mpg vs.
 weight', 
\end_layout

\begin_layout Plain Layout

     pch=16,col='cornflowerblue') 
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Looking at the plot, we find that a linear model would be a good fit for
 the dataset.
 We thus fit a linear model to the data: 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=F>>=
\end_layout

\begin_layout Plain Layout

model<-lm(df$mpg~df$weight) 
\end_layout

\begin_layout Plain Layout

summary(model) 
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
To look at whether our simple linear model assumption is right or not, we
 might plot the residuals on the y-axis and the predictor variables on the
 x-axis.
 The resultant plot is: 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=F>>=
\end_layout

\begin_layout Plain Layout

plot(df$weight,residuals(model), xlab='Weight', ylab='Residuals', 
\end_layout

\begin_layout Plain Layout

     main='Scatterplot of Residuals vs.
 Weight', pch=16,col='cyan3')
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We observe that the plot shows a stepped pattern which gives evidence that
 the simple-linear part in the simple linear model is wrong.
 Also, the there is a changing width which also points to the fact that
 the model is mis-specified.
 Thus, we either need more predictor variables, or a different model, or
 both.
 We can derive a similar result using the residual vs predicted value plot:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=F>>=
\end_layout

\begin_layout Plain Layout

plot(predict(model),residuals(model), xlab='Predicted', ylab='Residuals',
 
\end_layout

\begin_layout Plain Layout

     main='Scatterplot of Residuals vs.
 Predicted', pch=16,col='indianred1') 
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We observe that this plot is more similar to the previous one.
 The reason being the predicted values are a function of the covariates
 and thus, the graphs are similar.
 
\end_layout

\begin_layout Standard
Taking the log transformation of the covariate, we obtaing the following
 graph:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=F>>=
\end_layout

\begin_layout Plain Layout

plot(log(df$weight),df$mpg, 
\end_layout

\begin_layout Plain Layout

     xlab='log(Weight)', ylab='mpg', 
\end_layout

\begin_layout Plain Layout

     main='mpg vs.
 log(weight)', 
\end_layout

\begin_layout Plain Layout

     pch=16,col='mediumpurple') 
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This is a straight line once again, which suggests that the regression is
 not linear, but rather exponential.
 It also suggests that the normality assumption of the error terms was false
 previously.
 
\end_layout

\begin_layout Standard
We once again fit a linear regression on this transformed data and see if
 the residuals satisfy the normality assumption:
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=F>>=
\end_layout

\begin_layout Plain Layout

logmodel<-lm(df$mpg~log(df$weight)) 
\end_layout

\begin_layout Plain Layout

summary(logmodel) 
\end_layout

\begin_layout Plain Layout

qqnorm(residuals(logmodel), pch=19,col='paleturquoise4',bty='n') 
\end_layout

\begin_layout Plain Layout

qqline(residuals(logmodel)) 
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
As anticipated, the residuals do not satisfy the normality assumption.
 
\end_layout

\begin_layout Standard
Finally, we might use the Box-Cox transformation and refit our model using
 the appropriate transformation: 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=F>>=
\end_layout

\begin_layout Plain Layout

library(MASS) 
\end_layout

\begin_layout Plain Layout

bc.lm<-boxcox(df$mpg~df$weight) 
\end_layout

\begin_layout Plain Layout

(lambda.hat<-bc.lm$x[which.max(bc.lm$y)])
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We finally plot our Box-Cox transformed model with our estimated lambda:
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=F>>=
\end_layout

\begin_layout Plain Layout

df$bc.mpg<-((df$mpg^lambda.hat)-1)/lambda.hat 
\end_layout

\begin_layout Plain Layout

bc.lm<-lm(df$bc.mpg~df$weight) 
\end_layout

\begin_layout Plain Layout

plot(df$weight,df$mpg, pch=16,col='orchid1', 
\end_layout

\begin_layout Plain Layout

     xlab='Weight',ylab='mpg', main='mpg vs.
 weight') 
\end_layout

\begin_layout Plain Layout

points(df$weight,((lambda.hat*fitted(bc.lm))+1)^(1/lambda.hat), pch=19) 
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Among the three models, the Box-Cox transformed model looks the best fit.
 The slope of the model infers that if the weight is changed by one unit
 measure, on an average the mpg would change by (in units): 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=F>>=
\end_layout

\begin_layout Plain Layout

bc.lm$coefficients[2]
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can verify if the association between weight and mpg is linear or not.
 The null hypothesis being that the correlation is 0 with the alternative
 being that the correlation is not 0.
 Under the null hypothesis, the test statistic is 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
t=\frac{r\sqrt{n-2}}{\sqrt{1-r^{2}}}\sim t_{n-2}
\]

\end_inset


\end_layout

\begin_layout Standard
where r: sample correlation coefficient 
\end_layout

\begin_layout Standard
and n: number of observations.
 
\end_layout

\begin_layout Standard
We accept the null hypothesis if our p-value of the test > 0.05 else we reject
 the null hypothesis.
 In case the null hypothesis is rejected then we might assume that the associati
on between our variables is linear.
 We apply a correlation test on the variables and the result we obtained
 are as follows:
\end_layout

\end_body
\end_document
